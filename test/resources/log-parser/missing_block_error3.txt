Ivy Default Cache set to: /home/hadoop/.ivy2/cache
The jars for the packages stored in: /home/hadoop/.ivy2/jars
:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-69119251-4c6f-473f-b395-51da4fce818a;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central
	found org.apache.kafka#kafka-clients;2.4.1 in central
	found com.github.luben#zstd-jni;1.4.4-3 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.7.5 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 413ms :: artifacts dl 10ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.4-3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-69119251-4c6f-473f-b395-51da4fce818a
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/12ms)
21/03/21 15:38:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/21 15:38:44 INFO RMProxy: Connecting to ResourceManager at ip-96-113-30-100.nest.r53.xcal.tv/96.113.30.100:8032
21/03/21 15:38:44 INFO Client: Requesting a new application from cluster with 16 NodeManagers
21/03/21 15:38:44 INFO Configuration: resource-types.xml not found
21/03/21 15:38:44 INFO ResourceUtils: Unable to find 'resource-types.xml'.
21/03/21 15:38:44 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (57344 MB per container)
21/03/21 15:38:44 INFO Client: Will allocate AM container, with 4505 MB memory including 409 MB overhead
21/03/21 15:38:44 INFO Client: Setting up container launch context for our AM
21/03/21 15:38:44 INFO Client: Setting up the launch environment for our AM container
21/03/21 15:38:44 INFO Client: Preparing resources for our AM container
21/03/21 15:38:44 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
21/03/21 15:38:46 INFO Client: Uploading resource file:/mnt/tmp/spark-522b6328-0635-443d-9629-8522da2193b9/__spark_libs__1640971951506407.zip -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0009/__spark_libs__1640971951506407.zip
21/03/21 15:38:47 INFO Client: Uploading resource file:/home/hadoop/streaming-jobs-.snmp-assembly-2.0-SNAPSHOT.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0009/streaming-jobs-.snmp-assembly-2.0-SNAPSHOT.jar
21/03/21 15:38:47 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0009/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
21/03/21 15:38:47 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0009/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
21/03/21 15:38:47 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0009/org.apache.kafka_kafka-clients-2.4.1.jar
21/03/21 15:38:47 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0009/org.apache.commons_commons-pool2-2.6.2.jar
21/03/21 15:38:47 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0009/org.spark-project.spark_unused-1.0.0.jar
21/03/21 15:38:47 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0009/com.github.luben_zstd-jni-1.4.4-3.jar
21/03/21 15:38:47 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0009/org.lz4_lz4-java-1.7.1.jar
21/03/21 15:38:47 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0009/org.xerial.snappy_snappy-java-1.1.7.5.jar
21/03/21 15:38:47 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0009/org.slf4j_slf4j-api-1.7.30.jar
21/03/21 15:38:47 INFO Client: Uploading resource file:/mnt/tmp/spark-522b6328-0635-443d-9629-8522da2193b9/__spark_conf__3657483747468508323.zip -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0009/__spark_conf__.zip
21/03/21 15:38:47 INFO SecurityManager: Changing view acls to: hadoop
21/03/21 15:38:47 INFO SecurityManager: Changing modify acls to: hadoop
21/03/21 15:38:47 INFO SecurityManager: Changing view acls groups to:
21/03/21 15:38:47 INFO SecurityManager: Changing modify acls groups to:
21/03/21 15:38:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
21/03/21 15:38:47 INFO Client: Submitting application application_1616274464507_0009 to ResourceManager
21/03/21 15:38:47 INFO YarnClientImpl: Submitted application application_1616274464507_0009
21/03/21 15:38:48 INFO Client: Application report for application_1616274464507_0009 (state: ACCEPTED)
21/03/21 15:38:48 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1616341127829
	 final status: UNDEFINED
	 tracking URL: http://ip-96-113-30-100.nest.r53.xcal.tv:20888/proxy/application_1616274464507_0009/
	 user: hadoop
21/03/21 15:38:49 INFO Client: Application report for application_1616274464507_0009 (state: ACCEPTED)
21/03/21 15:38:50 INFO Client: Application report for application_1616274464507_0009 (state: ACCEPTED)
21/03/21 15:38:51 INFO Client: Application report for application_1616274464507_0009 (state: ACCEPTED)
21/03/21 15:38:52 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:38:52 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: ip-96-113-30-216.nest.r53.xcal.tv
	 ApplicationMaster RPC port: 41577
	 queue: default
	 start time: 1616341127829
	 final status: UNDEFINED
	 tracking URL: http://ip-96-113-30-100.nest.r53.xcal.tv:20888/proxy/application_1616274464507_0009/
	 user: hadoop
21/03/21 15:38:53 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:38:54 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:38:55 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:38:56 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:38:57 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:38:58 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:38:59 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:00 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:01 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:02 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:03 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:04 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:05 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:06 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:07 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:08 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:09 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:10 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:11 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:12 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:13 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:14 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:15 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:16 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:17 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:18 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:19 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:20 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:21 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:22 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:23 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:24 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:25 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:26 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:27 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:28 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:29 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:30 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:31 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:32 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:33 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:34 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:35 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:36 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:37 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:38 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:39 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:40 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:41 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:42 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:43 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:44 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:45 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:46 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:47 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:48 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:49 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:50 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:51 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:52 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:53 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:54 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:55 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:56 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:57 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:58 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:39:59 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:00 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:01 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:02 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:03 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:04 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:05 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:06 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:07 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:08 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:09 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:10 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:11 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:12 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:13 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:14 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:15 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:16 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:17 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:18 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:19 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:20 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:21 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:22 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:23 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:24 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:25 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:26 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:27 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:28 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:29 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:30 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:31 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:32 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:33 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:34 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:35 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:36 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:37 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:38 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:39 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:40 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:41 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:42 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:43 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:44 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:45 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:46 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:47 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:48 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:49 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:50 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:51 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:52 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:53 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:54 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:55 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:56 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:57 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:58 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:40:59 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:00 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:01 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:02 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:03 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:04 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:05 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:06 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:07 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:09 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:10 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:11 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:12 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:13 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:14 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:15 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:16 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:17 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:18 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:19 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:20 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:21 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:22 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:23 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:24 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:25 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:26 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:27 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:28 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:29 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:30 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:31 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:32 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:33 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:34 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:35 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:36 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:37 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:38 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:39 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:40 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:41 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:42 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:43 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:44 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:45 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:46 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:47 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:48 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:49 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:50 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:51 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:52 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:53 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:54 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:55 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:56 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:57 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:58 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:41:59 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:00 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:01 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:02 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:03 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:04 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:05 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:06 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:07 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:08 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:09 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:10 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:11 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:12 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:13 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:14 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:15 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:16 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:17 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:18 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:19 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:20 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:21 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:22 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:23 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:24 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:25 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:26 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:27 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:28 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:29 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:30 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:31 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:32 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:33 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:34 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:35 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:36 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:37 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:38 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:39 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:40 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:41 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:42 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:43 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:44 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:45 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:46 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:47 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:48 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:49 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:50 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:51 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:52 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:53 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:54 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:55 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:56 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:57 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:58 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:42:59 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:00 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:01 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:02 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:03 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:04 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:05 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:06 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:07 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:08 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:09 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:10 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:11 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:12 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:13 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:14 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:15 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:16 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:17 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:18 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:19 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:20 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:21 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:22 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:23 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:24 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:25 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:26 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:27 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:28 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:29 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:30 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:31 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:32 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:33 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:34 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:35 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:36 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:37 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:38 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:39 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:40 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:41 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:42 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:43 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:44 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:45 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:46 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:47 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:48 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:49 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:50 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:51 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:52 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:53 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:54 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:55 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:56 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:57 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:58 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:43:59 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:00 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:01 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:02 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:03 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:04 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:05 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:06 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:07 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:08 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:09 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:10 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:11 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:12 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:13 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:14 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:15 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:16 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:17 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:18 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:19 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:20 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:21 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:22 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:23 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:24 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:25 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:26 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:27 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:28 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:29 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:30 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:31 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:32 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:33 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:34 INFO Client: Application report for application_1616274464507_0009 (state: RUNNING)
21/03/21 15:44:35 INFO Client: Application report for application_1616274464507_0009 (state: FINISHED)
21/03/21 15:44:35 INFO Client:
	 client token: N/A
	 diagnostics: Diagnostic messages truncated, showing last 65536 chars out of 80932:
...tringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#838: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
      +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#837: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
         +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#728, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#729, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#730, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#731L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#732, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#733, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#734, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#735, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#736, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#737, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#738, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#739, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#740, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#741, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#742, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#743L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#744, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#745, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#746, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#747, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIp, true, false) AS neighborIp#748, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifIndex AS ifIndex#749, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuType, true, false) AS cpuType#750, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuName, true, false) AS cpuName#751, ... 12 more fields]
            +- MapElements yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1624/164695843@8bfe866, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#727: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
               +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#726: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                  +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#617, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#618, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#619, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#620L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#621, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#622, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#623, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#624, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#625, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#626, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#627, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#628, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#629, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#630, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#631, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#632L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#633, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#634, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#635, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#636, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIp, true, false) AS neighborIp#637, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifIndex AS ifIndex#638, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuType, true, false) AS cpuType#639, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuName, true, false) AS cpuName#640, ... 12 more fields]
                     +- MapElements yet.another.company.core.metrics.LongValStatsAccumulator$$Lambda$1622/694802800@e16c650, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#616: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                        +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#615: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                           +- TypedFilter yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1619/2025013765@307d3e2b, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState)
                              +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#469, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#470, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#471, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#472L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#473, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#474, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#475, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#476, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#477, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#478, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#479, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#480, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#481, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#482, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#483, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#484L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#485, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#486, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#487, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#488, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIp, true, false) AS neighborIp#489, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifIndex AS ifIndex#490, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuType, true, false) AS cpuType#491, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuName, true, false) AS cpuName#492, ... 12 more fields]
                                 +- MapElements yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1618/899786312@6798aaa3, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#468: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                                    +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#467: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                                       +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#358, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#359, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#360, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#361L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#362, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#363, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#364, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#365, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#366, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#367, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#368, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#369, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#370, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#371, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#372, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#373L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#374, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#375, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#376, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#377, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIp, true, false) AS neighborIp#378, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifIndex AS ifIndex#379, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuType, true, false) AS cpuType#380, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuName, true, false) AS cpuName#381, ... 12 more fields]
                                          +- FlatMapGroupsWithState yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1610/565771283@3530c783, cast(value#284 as string).toString, newInstance(class yet.another.company.snmp.dto.RichSnmpRecord), [value#284], [deviceId#254, deviceName#255, deviceIp#256, objectName#257, ifDesc#258, indicatorName#259, value#260, time#261L, pluginName#262, vendor#263, model#264, neighborFqdn#265, neighborIfName#266, neighborIp#267, ifIndex#268, id#269, sourceType#270, cpuType#271, cpuName#272, ifName#273, division#274, metric#275, status#276, bandwidth#277L, ... 5 more fields], obj#357: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, class[uuid[0]: string, id[0]: string, currValue[0]: decimal(38,18), time[0]: bigint, updated[0]: boolean, isDiff[0]: boolean, diffValue[0]: double, deviceName[0]: string, deviceIp[0]: string, ifName[0]: string, ifDesc[0]: string, indicatorName[0]: string, objectName[0]: string, division[0]: string, sourceType[0]: string, prevTime[0]: bigint, vendor[0]: string, model[0]: string, neighborFqdn[0]: string, neighborIfName[0]: string, neighborIp[0]: string, ifIndex[0]: int, cpuType[0]: string, cpuName[0]: string, status[0]: struct<underMaintenance:boolean,inInventory:boolean,neighborUnderMaintenance:boolean>, metric[0]: string, tags[0]: map<string,string>, sysId[0]: string, rate[0]: double, bandwidth[0]: bigint, connectionId[0]: string, history[0]: array<struct<time:bigint,value:decimal(38,18)>>, metaInfo[0]: struct<batchId:bigint>, historyRecords[0]: array<struct<ruleId:string,ruleDescription:string,workflowId:string,className:string,nodeIp:string,eventTime:string>>, forAlarms[0]: boolean, eventLevel[0]: string], Update, false, NoTimeout
                                             +- AppendColumns yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1608/2080964359@3cd856f5, class yet.another.company.snmp.dto.RichSnmpRecord, [StructField(deviceId,IntegerType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(objectName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(value,DecimalType(38,18),true), StructField(time,LongType,false), StructField(pluginName,StringType,true), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(id,StringType,true), StructField(sourceType,StringType,true), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), StructField(ifName,StringType,true), StructField(division,StringType,true), StructField(metric,StringType,true), StructField(status,StructType(StructField(underMaintenance,BooleanType,false), StructField(inInventory,BooleanType,false), StructField(neighborUnderMaintenance,BooleanType,true)),true), StructField(bandwidth,LongType,false), ... 5 more fields], newInstance(class yet.another.company.snmp.dto.RichSnmpRecord), [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, input[0, java.lang.String, true], true, false) AS value#284]
                                                +- SerializeFromObject [knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).deviceId AS deviceId#254, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).deviceName, true, false) AS deviceName#255, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).deviceIp, true, false) AS deviceIp#256, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).objectName, true, false) AS objectName#257, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).ifDesc, true, false) AS ifDesc#258, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).indicatorName, true, false) AS indicatorName#259, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).value AS value#260, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).time AS time#261L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).pluginName, true, false) AS pluginName#262, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).vendor, true, false) AS vendor#263, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).model, true, false) AS model#264, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).neighborFqdn, true, false) AS neighborFqdn#265, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).neighborIfName, true, false) AS neighborIfName#266, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).neighborIp, true, false) AS neighborIp#267, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).ifIndex AS ifIndex#268, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).id, true, false) AS id#269, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).sourceType, true, false) AS sourceType#270, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).cpuType, true, false) AS cpuType#271, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).cpuName, true, false) AS cpuName#272, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).ifName, true, false) AS ifName#273, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).division, true, false) AS division#274, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).metric, true, false) AS metric#275, if (isnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status)) null else named_struct(underMaintenance, knownnotnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status).underMaintenance, inInventory, knownnotnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status).inInventory, neighborUnderMaintenance, unwrapoption(BooleanType, knownnotnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status).neighborUnderMaintenance)) AS status#276, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).bandwidth AS bandwidth#277L, ... 5 more fields]
                                                   +- MapPartitions org.apache.spark.sql.Dataset$$Lambda$1397/1260246447@546bc3cf, obj#253: yet.another.company.snmp.dto.RichSnmpRecord
                                                      +- DeserializeToObject newInstance(class yet.another.company.snmp.dto.RichSnmpRecord), obj#252: yet.another.company.snmp.dto.RichSnmpRecord
                                                         +- SerializeFromObject [knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).deviceId AS deviceId#194, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).deviceName, true, false) AS deviceName#195, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).deviceIp, true, false) AS deviceIp#196, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).objectName, true, false) AS objectName#197, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).ifDesc, true, false) AS ifDesc#198, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).indicatorName, true, false) AS indicatorName#199, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).value AS value#200, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).time AS time#201L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).pluginName, true, false) AS pluginName#202, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).vendor, true, false) AS vendor#203, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).model, true, false) AS model#204, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).neighborFqdn, true, false) AS neighborFqdn#205, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).neighborIfName, true, false) AS neighborIfName#206, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).neighborIp, true, false) AS neighborIp#207, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).ifIndex AS ifIndex#208, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).id, true, false) AS id#209, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).sourceType, true, false) AS sourceType#210, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).cpuType, true, false) AS cpuType#211, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).cpuName, true, false) AS cpuName#212, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).ifName, true, false) AS ifName#213, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).division, true, false) AS division#214, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).metric, true, false) AS metric#215, if (isnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status)) null else named_struct(underMaintenance, knownnotnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status).underMaintenance, inInventory, knownnotnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status).inInventory, neighborUnderMaintenance, unwrapoption(BooleanType, knownnotnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status).neighborUnderMaintenance)) AS status#216, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).bandwidth AS bandwidth#217L, ... 5 more fields]
                                                            +- MapPartitions org.apache.spark.sql.Dataset$$Lambda$1397/1260246447@59a39955, obj#193: yet.another.company.snmp.dto.RichSnmpRecord
                                                               +- DeserializeToObject newInstance(class yet.another.company.snmp.streaming.InputSevOneRecord), obj#192: yet.another.company.snmp.streaming.InputSevOneRecord
                                                                  +- Union
                                                                     :- TypedFilter yet.another.company.snmp.streaming.SnmpStreaming$$$Lambda$1414/2023740540@21f1e6b6, class yet.another.company.snmp.streaming.InputSevOneRecord, [StructField(deviceId,IntegerType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(peerId,IntegerType,false), StructField(objectId,IntegerType,false), StructField(objectName,StringType,true), StructField(objectDesc,StringType,true), StructField(pluginId,IntegerType,false), StructField(pluginName,StringType,true), StructField(indicatorId,IntegerType,false), StructField(indicatorName,StringType,true), StructField(format,IntegerType,false), StructField(value,StringType,true), StructField(time,DoubleType,false), StructField(clusterName,StringType,true), StructField(peerIp,StringType,true)], newInstance(class yet.another.company.snmp.streaming.InputSevOneRecord)
                                                                     :  +- SerializeFromObject [knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).deviceId AS deviceId#40, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).deviceName, true, false) AS deviceName#41, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).deviceIp, true, false) AS deviceIp#42, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).peerId AS peerId#43, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).objectId AS objectId#44, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).objectName, true, false) AS objectName#45, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).objectDesc, true, false) AS objectDesc#46, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).pluginId AS pluginId#47, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).pluginName, true, false) AS pluginName#48, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).indicatorId AS indicatorId#49, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).indicatorName, true, false) AS indicatorName#50, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).format AS format#51, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).value, true, false) AS value#52, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).time AS time#53, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).clusterName, true, false) AS clusterName#54, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).peerIp, true, false) AS peerIp#55]
                                                                     :     +- MapPartitions org.apache.spark.sql.Dataset$$Lambda$1397/1260246447@2641b369, obj#39: yet.another.company.snmp.streaming.InputSevOneRecord
                                                                     :        +- DeserializeToObject cast(value#8 as binary), obj#38: binary
                                                                     :           +- Project [value#8]
                                                                     :              +- StreamingDataSourceV2Relation [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan@7a278fda, KafkaV2[Subscribe[sevone-spdb]]
                                                                     +- TypedFilter yet.another.company.snmp.streaming.SnmpStreaming$$$Lambda$1414/2023740540@21f1e6b6, class yet.another.company.snmp.streaming.InputSevOneRecord, [StructField(deviceId,IntegerType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(peerId,IntegerType,false), StructField(objectId,IntegerType,false), StructField(objectName,StringType,true), StructField(objectDesc,StringType,true), StructField(pluginId,IntegerType,false), StructField(pluginName,StringType,true), StructField(indicatorId,IntegerType,false), StructField(indicatorName,StringType,true), StructField(format,IntegerType,false), StructField(value,StringType,true), StructField(time,DoubleType,false), StructField(clusterName,StringType,true), StructField(peerIp,StringType,true)], newInstance(class yet.another.company.snmp.streaming.InputSevOneRecord)
                                                                        +- SerializeFromObject [knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).deviceId AS deviceId#113, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).deviceName, true, false) AS deviceName#114, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).deviceIp, true, false) AS deviceIp#115, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).peerId AS peerId#116, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).objectId AS objectId#117, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).objectName, true, false) AS objectName#118, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).objectDesc, true, false) AS objectDesc#119, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).pluginId AS pluginId#120, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).pluginName, true, false) AS pluginName#121, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).indicatorId AS indicatorId#122, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).indicatorName, true, false) AS indicatorName#123, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).format AS format#124, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).value, true, false) AS value#125, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).time AS time#126, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).clusterName, true, false) AS clusterName#127, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).peerIp, true, false) AS peerIp#128]
                                                                           +- MapPartitions org.apache.spark.sql.Dataset$$Lambda$1397/1260246447@6f922843, obj#112: yet.another.company.snmp.streaming.InputSevOneRecord
                                                                              +- DeserializeToObject cast(value#81 as binary), obj#111: binary
                                                                                 +- Project [value#81]
                                                                                    +- StreamingDataSourceV2Relation [key#80, value#81, topic#82, partition#83, offset#84L, timestamp#85, timestampType#86], org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan@5848ef8f, KafkaV2[Subscribe[sevone-spdb]]

	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:355)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:245)
Caused by: org.apache.spark.SparkException: Writing job aborted.
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:413)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:361)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:322)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:329)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:39)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:39)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:45)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3676)
	at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:2980)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3667)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:104)
	at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:227)
	at org.apache.spark.sql.execution.SQLExecution$.executeQuery$1(SQLExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:132)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:104)
	at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:227)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:132)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:248)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:131)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:68)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3665)
	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2980)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:575)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:104)
	at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:227)
	at org.apache.spark.sql.execution.SQLExecution$.executeQuery$1(SQLExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:132)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:104)
	at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:227)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:132)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:248)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:131)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:68)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$15(MicroBatchExecution.scala:570)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:352)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:350)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:69)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:570)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:223)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:352)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:350)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:69)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:191)
	at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:185)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:334)
	... 1 more
Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 111 in stage 1.0 failed 4 times, most recent failure: Lost task 111.3 in stage 1.0 (TID 873, ip-96-113-30-162.nest.r53.xcal.tv, executor 15): org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-735645629-96.113.30.100-1616274425646:blk_1073825893_85207 file=/streaming-jobs--checkpoints/state/0/111/319.snapshot
	at org.apache.hadoop.hdfs.DFSInputStream.refetchLocations(DFSInputStream.java:879)
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:862)
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:841)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:567)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:757)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at net.jpountz.lz4.LZ4BlockInputStream.tryReadFully(LZ4BlockInputStream.java:269)
	at net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:190)
	at net.jpountz.lz4.LZ4BlockInputStream.read(LZ4BlockInputStream.java:142)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.readSnapshotFile(HDFSBackedStateStoreProvider.scala:528)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$3(HDFSBackedStateStoreProvider.scala:376)
	at scala.Option.orElse(Option.scala:447)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$2(HDFSBackedStateStoreProvider.scala:376)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:561)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.loadMap(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getStore(HDFSBackedStateStoreProvider.scala:204)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.get(StateStore.scala:371)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:90)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2215)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2164)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2163)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2163)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1013)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1013)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1013)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2395)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2344)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2333)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:815)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:382)
	... 49 more
Caused by: org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-735645629-96.113.30.100-1616274425646:blk_1073825893_85207 file=/streaming-jobs--checkpoints/state/0/111/319.snapshot
	at org.apache.hadoop.hdfs.DFSInputStream.refetchLocations(DFSInputStream.java:879)
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:862)
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:841)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:567)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:757)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at net.jpountz.lz4.LZ4BlockInputStream.tryReadFully(LZ4BlockInputStream.java:269)
	at net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:190)
	at net.jpountz.lz4.LZ4BlockInputStream.read(LZ4BlockInputStream.java:142)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.readSnapshotFile(HDFSBackedStateStoreProvider.scala:528)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$3(HDFSBackedStateStoreProvider.scala:376)
	at scala.Option.orElse(Option.scala:447)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$2(HDFSBackedStateStoreProvider.scala:376)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:561)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.loadMap(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getStore(HDFSBackedStateStoreProvider.scala:204)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.get(StateStore.scala:371)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:90)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

	 ApplicationMaster host: ip-96-113-30-216.nest.r53.xcal.tv
	 ApplicationMaster RPC port: 41577
	 queue: default
	 start time: 1616341127829
	 final status: FAILED
	 tracking URL: http://ip-96-113-30-100.nest.r53.xcal.tv:20888/proxy/application_1616274464507_0009/
	 user: hadoop
21/03/21 15:44:35 ERROR Client: Application diagnostics message: Diagnostic messages truncated, showing last 65536 chars out of 80932:
...tringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#838: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
      +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#837: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
         +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#728, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#729, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#730, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#731L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#732, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#733, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#734, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#735, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#736, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#737, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#738, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#739, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#740, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#741, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#742, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#743L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#744, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#745, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#746, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#747, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIp, true, false) AS neighborIp#748, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifIndex AS ifIndex#749, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuType, true, false) AS cpuType#750, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuName, true, false) AS cpuName#751, ... 12 more fields]
            +- MapElements yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1624/164695843@8bfe866, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#727: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
               +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#726: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                  +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#617, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#618, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#619, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#620L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#621, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#622, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#623, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#624, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#625, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#626, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#627, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#628, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#629, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#630, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#631, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#632L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#633, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#634, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#635, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#636, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIp, true, false) AS neighborIp#637, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifIndex AS ifIndex#638, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuType, true, false) AS cpuType#639, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuName, true, false) AS cpuName#640, ... 12 more fields]
                     +- MapElements yet.another.company.core.metrics.LongValStatsAccumulator$$Lambda$1622/694802800@e16c650, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#616: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                        +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#615: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                           +- TypedFilter yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1619/2025013765@307d3e2b, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState)
                              +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#469, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#470, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#471, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#472L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#473, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#474, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#475, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#476, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#477, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#478, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#479, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#480, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#481, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#482, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#483, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#484L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#485, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#486, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#487, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#488, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggStaCommand exiting with ret '1'