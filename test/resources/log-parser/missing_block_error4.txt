Ivy Default Cache set to: /home/hadoop/.ivy2/cache
The jars for the packages stored in: /home/hadoop/.ivy2/jars
:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-a3b300c7-7c44-4455-89a1-cb81d792beb4;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central
	found org.apache.kafka#kafka-clients;2.4.1 in central
	found com.github.luben#zstd-jni;1.4.4-3 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.7.5 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 578ms :: artifacts dl 24ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.4-3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-a3b300c7-7c44-4455-89a1-cb81d792beb4
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/11ms)
21/03/21 14:39:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/21 14:39:47 INFO RMProxy: Connecting to ResourceManager at ip-96-113-30-100.nest.r53.xcal.tv/96.113.30.100:8032
21/03/21 14:39:47 INFO Client: Requesting a new application from cluster with 16 NodeManagers
21/03/21 14:39:48 INFO Configuration: resource-types.xml not found
21/03/21 14:39:48 INFO ResourceUtils: Unable to find 'resource-types.xml'.
21/03/21 14:39:48 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (57344 MB per container)
21/03/21 14:39:48 INFO Client: Will allocate AM container, with 4505 MB memory including 409 MB overhead
21/03/21 14:39:48 INFO Client: Setting up container launch context for our AM
21/03/21 14:39:48 INFO Client: Setting up the launch environment for our AM container
21/03/21 14:39:48 INFO Client: Preparing resources for our AM container
21/03/21 14:39:48 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
21/03/21 14:39:50 INFO Client: Uploading resource file:/mnt/tmp/spark-e114c253-d69f-4dfb-9456-eade86e01e13/__spark_libs__661243366704509504.zip -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0002/__spark_libs__661243366704509504.zip
21/03/21 14:39:51 INFO Client: Uploading resource file:/home/hadoop/streaming-jobs-.snmp-assembly-2.0-SNAPSHOT.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0002/streaming-jobs-.snmp-assembly-2.0-SNAPSHOT.jar
21/03/21 14:39:51 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0002/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
21/03/21 14:39:51 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0002/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
21/03/21 14:39:51 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0002/org.apache.kafka_kafka-clients-2.4.1.jar
21/03/21 14:39:51 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0002/org.apache.commons_commons-pool2-2.6.2.jar
21/03/21 14:39:51 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0002/org.spark-project.spark_unused-1.0.0.jar
21/03/21 14:39:51 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0002/com.github.luben_zstd-jni-1.4.4-3.jar
21/03/21 14:39:51 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0002/org.lz4_lz4-java-1.7.1.jar
21/03/21 14:39:51 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0002/org.xerial.snappy_snappy-java-1.1.7.5.jar
21/03/21 14:39:51 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0002/org.slf4j_slf4j-api-1.7.30.jar
21/03/21 14:39:51 INFO Client: Uploading resource file:/mnt/tmp/spark-e114c253-d69f-4dfb-9456-eade86e01e13/__spark_conf__2883768652474965151.zip -> hdfs://ip-96-113-30-100.nest.r53.xcal.tv:8020/user/hadoop/.sparkStaging/application_1616274464507_0002/__spark_conf__.zip
21/03/21 14:39:51 INFO SecurityManager: Changing view acls to: hadoop
21/03/21 14:39:51 INFO SecurityManager: Changing modify acls to: hadoop
21/03/21 14:39:51 INFO SecurityManager: Changing view acls groups to:
21/03/21 14:39:51 INFO SecurityManager: Changing modify acls groups to:
21/03/21 14:39:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
21/03/21 14:39:52 INFO Client: Submitting application application_1616274464507_0002 to ResourceManager
21/03/21 14:39:52 INFO YarnClientImpl: Submitted application application_1616274464507_0002
21/03/21 14:39:53 INFO Client: Application report for application_1616274464507_0002 (state: ACCEPTED)
21/03/21 14:39:53 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1616337592025
	 final status: UNDEFINED
	 tracking URL: http://ip-96-113-30-100.nest.r53.xcal.tv:20888/proxy/application_1616274464507_0002/
	 user: hadoop
21/03/21 14:39:54 INFO Client: Application report for application_1616274464507_0002 (state: ACCEPTED)
21/03/21 14:39:55 INFO Client: Application report for application_1616274464507_0002 (state: ACCEPTED)
21/03/21 14:39:56 INFO Client: Application report for application_1616274464507_0002 (state: ACCEPTED)
21/03/21 14:39:57 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:39:57 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: ip-96-113-30-138.nest.r53.xcal.tv
	 ApplicationMaster RPC port: 40747
	 queue: default
	 start time: 1616337592025
	 final status: UNDEFINED
	 tracking URL: http://ip-96-113-30-100.nest.r53.xcal.tv:20888/proxy/application_1616274464507_0002/
	 user: hadoop
21/03/21 14:39:58 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:39:59 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:00 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:01 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:02 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:03 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:04 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:05 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:06 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:07 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:08 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:09 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:10 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:11 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:12 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:13 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:14 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:15 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:16 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:17 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:18 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:19 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:20 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:21 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:22 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:23 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:24 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:25 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:26 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:27 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:28 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:29 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:30 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:31 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:32 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:33 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:34 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:35 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:36 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:37 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:38 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:39 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:40 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:41 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:42 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:43 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:44 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:45 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:46 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:47 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:48 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:49 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:50 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:51 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:52 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:53 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:54 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:55 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:56 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:57 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:58 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:40:59 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:00 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:01 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:02 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:03 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:04 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:05 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:06 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:07 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:08 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:09 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:10 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:11 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:12 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:13 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:14 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:15 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:16 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:17 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:18 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:19 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:20 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:21 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:22 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:23 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:24 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:25 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:26 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:27 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:28 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:29 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:30 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:31 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:32 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:33 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:34 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:35 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:36 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:37 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:38 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:39 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:40 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:41 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:42 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:43 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:44 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:45 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:46 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:47 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:48 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:49 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:50 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:51 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:52 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:53 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:54 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:55 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:56 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:57 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:58 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:41:59 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:00 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:01 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:02 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:03 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:04 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:05 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:06 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:07 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:08 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:09 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:10 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:11 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:12 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:13 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:14 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:15 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:16 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:17 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:18 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:19 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:20 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:21 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:22 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:23 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:24 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:25 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:26 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:27 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:28 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:29 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:30 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:31 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:32 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:33 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:34 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:35 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:36 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:37 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:38 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:39 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:40 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:41 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:42 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:43 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:44 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:45 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:46 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:47 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:48 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:49 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:50 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:51 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:52 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:53 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:54 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:55 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:56 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:57 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:58 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:42:59 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:00 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:01 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:02 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:03 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:04 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:05 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:06 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:07 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:08 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:09 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:10 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:11 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:12 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:13 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:14 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:15 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:16 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:17 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:18 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:19 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:20 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:21 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:22 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:23 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:24 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:25 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:26 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:27 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:28 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:29 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:30 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:31 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:32 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:33 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:34 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:35 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:36 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:37 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:38 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:39 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:40 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:41 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:42 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:43 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:44 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:45 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:46 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:47 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:48 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:49 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:50 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:51 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:52 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:53 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:54 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:55 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:56 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:57 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:58 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:43:59 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:00 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:01 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:02 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:03 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:04 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:05 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:06 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:07 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:08 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:09 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:10 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:11 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:12 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:13 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:14 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:15 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:16 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:17 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:18 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:19 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:20 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:21 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:22 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:23 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:24 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:25 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:26 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:27 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:28 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:29 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:30 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:31 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:32 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:33 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:34 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:35 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:36 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:37 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:38 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:39 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:40 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:41 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:42 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:43 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:44 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:45 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:46 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:47 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:48 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:49 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:50 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:51 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:52 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:53 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:54 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:55 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:56 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:57 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:58 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:44:59 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:00 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:01 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:02 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:03 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:04 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:05 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:06 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:07 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:08 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:09 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:10 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:11 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:12 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:13 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:14 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:15 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:16 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:17 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:18 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:19 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:20 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:21 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:22 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:23 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:24 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:25 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:26 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:27 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:28 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:29 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:30 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:31 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:32 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:33 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:34 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:35 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:36 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:37 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:38 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:39 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:40 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:41 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:42 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:43 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:44 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:45 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:46 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:47 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:48 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:49 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:50 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:51 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:52 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:53 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:54 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:55 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:56 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:57 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:58 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:45:59 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:00 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:01 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:02 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:03 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:04 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:05 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:06 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:07 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:08 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:09 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:10 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:11 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:12 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:13 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:14 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:15 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:16 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:17 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:18 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:19 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:20 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:21 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:22 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:23 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:24 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:25 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:26 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:27 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:28 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:29 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:30 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:31 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:32 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:33 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:34 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:35 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:36 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:37 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:38 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:39 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:40 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:41 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:42 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:43 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:44 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:45 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:46 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:47 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:48 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:49 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:50 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:51 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:52 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:53 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:54 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:55 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:56 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:57 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:58 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:46:59 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:00 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:01 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:02 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:03 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:04 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:05 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:06 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:07 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:08 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:09 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:10 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:11 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:12 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:13 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:14 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:15 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:16 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:17 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:18 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:19 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:20 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:21 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:22 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:23 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:24 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:25 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:26 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:27 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:28 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:29 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:30 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:31 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:32 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:33 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:34 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:35 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:36 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:37 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:38 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:39 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:40 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:41 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:42 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:43 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:44 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:45 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:46 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:47 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:48 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:49 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:50 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:51 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:52 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:53 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:54 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:55 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:56 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:57 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:58 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:47:59 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:48:00 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:48:01 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:48:02 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:48:03 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:48:04 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:48:05 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:48:06 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:48:07 INFO Client: Application report for application_1616274464507_0002 (state: RUNNING)
21/03/21 14:48:08 INFO Client: Application report for application_1616274464507_0002 (state: FINISHED)
21/03/21 14:48:08 INFO Client:
	 client token: N/A
	 diagnostics: Diagnostic messages truncated, showing last 65536 chars out of 80927:
...qdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#838: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
      +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#837: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
         +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#728, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#729, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#730, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#731L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#732, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#733, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#734, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#735, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#736, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#737, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#738, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#739, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#740, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#741, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#742, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#743L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#744, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#745, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#746, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#747, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIp, true, false) AS neighborIp#748, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifIndex AS ifIndex#749, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuType, true, false) AS cpuType#750, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuName, true, false) AS cpuName#751, ... 12 more fields]
            +- MapElements yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1635/308083037@34eab33, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#727: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
               +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#726: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                  +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#617, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#618, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#619, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#620L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#621, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#622, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#623, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#624, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#625, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#626, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#627, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#628, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#629, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#630, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#631, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#632L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#633, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#634, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#635, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#636, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIp, true, false) AS neighborIp#637, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifIndex AS ifIndex#638, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuType, true, false) AS cpuType#639, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuName, true, false) AS cpuName#640, ... 12 more fields]
                     +- MapElements yet.another.company.core.metrics.LongValStatsAccumulator$$Lambda$1633/484875948@7fe58c04, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#616: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                        +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#615: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                           +- TypedFilter yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1630/1394587108@232aa65a, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState)
                              +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#469, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#470, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#471, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#472L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#473, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#474, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#475, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#476, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#477, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#478, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#479, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#480, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#481, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#482, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#483, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#484L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#485, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#486, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#487, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#488, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIp, true, false) AS neighborIp#489, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifIndex AS ifIndex#490, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuType, true, false) AS cpuType#491, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuName, true, false) AS cpuName#492, ... 12 more fields]
                                 +- MapElements yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1629/1058405252@7f200df4, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#468: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                                    +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#467: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                                       +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#358, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#359, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#360, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#361L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#362, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#363, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#364, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#365, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#366, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#367, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#368, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#369, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#370, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#371, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#372, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#373L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#374, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#375, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#376, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#377, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIp, true, false) AS neighborIp#378, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifIndex AS ifIndex#379, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuType, true, false) AS cpuType#380, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuName, true, false) AS cpuName#381, ... 12 more fields]
                                          +- FlatMapGroupsWithState yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1621/1779687964@58bc59dc, cast(value#284 as string).toString, newInstance(class yet.another.company.snmp.dto.RichSnmpRecord), [value#284], [deviceId#254, deviceName#255, deviceIp#256, objectName#257, ifDesc#258, indicatorName#259, value#260, time#261L, pluginName#262, vendor#263, model#264, neighborFqdn#265, neighborIfName#266, neighborIp#267, ifIndex#268, id#269, sourceType#270, cpuType#271, cpuName#272, ifName#273, division#274, metric#275, status#276, bandwidth#277L, ... 5 more fields], obj#357: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, class[uuid[0]: string, id[0]: string, currValue[0]: decimal(38,18), time[0]: bigint, updated[0]: boolean, isDiff[0]: boolean, diffValue[0]: double, deviceName[0]: string, deviceIp[0]: string, ifName[0]: string, ifDesc[0]: string, indicatorName[0]: string, objectName[0]: string, division[0]: string, sourceType[0]: string, prevTime[0]: bigint, vendor[0]: string, model[0]: string, neighborFqdn[0]: string, neighborIfName[0]: string, neighborIp[0]: string, ifIndex[0]: int, cpuType[0]: string, cpuName[0]: string, status[0]: struct<underMaintenance:boolean,inInventory:boolean,neighborUnderMaintenance:boolean>, metric[0]: string, tags[0]: map<string,string>, sysId[0]: string, rate[0]: double, bandwidth[0]: bigint, connectionId[0]: string, history[0]: array<struct<time:bigint,value:decimal(38,18)>>, metaInfo[0]: struct<batchId:bigint>, historyRecords[0]: array<struct<ruleId:string,ruleDescription:string,workflowId:string,className:string,nodeIp:string,eventTime:string>>, forAlarms[0]: boolean, eventLevel[0]: string], Update, false, NoTimeout
                                             +- AppendColumns yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1619/313560769@3dae8418, class yet.another.company.snmp.dto.RichSnmpRecord, [StructField(deviceId,IntegerType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(objectName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(value,DecimalType(38,18),true), StructField(time,LongType,false), StructField(pluginName,StringType,true), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(id,StringType,true), StructField(sourceType,StringType,true), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), StructField(ifName,StringType,true), StructField(division,StringType,true), StructField(metric,StringType,true), StructField(status,StructType(StructField(underMaintenance,BooleanType,false), StructField(inInventory,BooleanType,false), StructField(neighborUnderMaintenance,BooleanType,true)),true), StructField(bandwidth,LongType,false), ... 5 more fields], newInstance(class yet.another.company.snmp.dto.RichSnmpRecord), [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, input[0, java.lang.String, true], true, false) AS value#284]
                                                +- SerializeFromObject [knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).deviceId AS deviceId#254, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).deviceName, true, false) AS deviceName#255, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).deviceIp, true, false) AS deviceIp#256, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).objectName, true, false) AS objectName#257, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).ifDesc, true, false) AS ifDesc#258, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).indicatorName, true, false) AS indicatorName#259, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).value AS value#260, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).time AS time#261L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).pluginName, true, false) AS pluginName#262, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).vendor, true, false) AS vendor#263, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).model, true, false) AS model#264, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).neighborFqdn, true, false) AS neighborFqdn#265, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).neighborIfName, true, false) AS neighborIfName#266, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).neighborIp, true, false) AS neighborIp#267, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).ifIndex AS ifIndex#268, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).id, true, false) AS id#269, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).sourceType, true, false) AS sourceType#270, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).cpuType, true, false) AS cpuType#271, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).cpuName, true, false) AS cpuName#272, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).ifName, true, false) AS ifName#273, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).division, true, false) AS division#274, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).metric, true, false) AS metric#275, if (isnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status)) null else named_struct(underMaintenance, knownnotnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status).underMaintenance, inInventory, knownnotnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status).inInventory, neighborUnderMaintenance, unwrapoption(BooleanType, knownnotnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status).neighborUnderMaintenance)) AS status#276, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).bandwidth AS bandwidth#277L, ... 5 more fields]
                                                   +- MapPartitions org.apache.spark.sql.Dataset$$Lambda$1408/1360791649@4b8ef9be, obj#253: yet.another.company.snmp.dto.RichSnmpRecord
                                                      +- DeserializeToObject newInstance(class yet.another.company.snmp.dto.RichSnmpRecord), obj#252: yet.another.company.snmp.dto.RichSnmpRecord
                                                         +- SerializeFromObject [knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).deviceId AS deviceId#194, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).deviceName, true, false) AS deviceName#195, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).deviceIp, true, false) AS deviceIp#196, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).objectName, true, false) AS objectName#197, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).ifDesc, true, false) AS ifDesc#198, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).indicatorName, true, false) AS indicatorName#199, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).value AS value#200, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).time AS time#201L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).pluginName, true, false) AS pluginName#202, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).vendor, true, false) AS vendor#203, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).model, true, false) AS model#204, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).neighborFqdn, true, false) AS neighborFqdn#205, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).neighborIfName, true, false) AS neighborIfName#206, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).neighborIp, true, false) AS neighborIp#207, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).ifIndex AS ifIndex#208, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).id, true, false) AS id#209, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).sourceType, true, false) AS sourceType#210, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).cpuType, true, false) AS cpuType#211, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).cpuName, true, false) AS cpuName#212, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).ifName, true, false) AS ifName#213, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).division, true, false) AS division#214, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).metric, true, false) AS metric#215, if (isnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status)) null else named_struct(underMaintenance, knownnotnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status).underMaintenance, inInventory, knownnotnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status).inInventory, neighborUnderMaintenance, unwrapoption(BooleanType, knownnotnull(knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).status).neighborUnderMaintenance)) AS status#216, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dto.RichSnmpRecord, true])).bandwidth AS bandwidth#217L, ... 5 more fields]
                                                            +- MapPartitions org.apache.spark.sql.Dataset$$Lambda$1408/1360791649@1fa3d1f6, obj#193: yet.another.company.snmp.dto.RichSnmpRecord
                                                               +- DeserializeToObject newInstance(class yet.another.company.snmp.streaming.InputSevOneRecord), obj#192: yet.another.company.snmp.streaming.InputSevOneRecord
                                                                  +- Union
                                                                     :- TypedFilter yet.another.company.snmp.streaming.SnmpStreaming$$$Lambda$1425/721212816@7fc33109, class yet.another.company.snmp.streaming.InputSevOneRecord, [StructField(deviceId,IntegerType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(peerId,IntegerType,false), StructField(objectId,IntegerType,false), StructField(objectName,StringType,true), StructField(objectDesc,StringType,true), StructField(pluginId,IntegerType,false), StructField(pluginName,StringType,true), StructField(indicatorId,IntegerType,false), StructField(indicatorName,StringType,true), StructField(format,IntegerType,false), StructField(value,StringType,true), StructField(time,DoubleType,false), StructField(clusterName,StringType,true), StructField(peerIp,StringType,true)], newInstance(class yet.another.company.snmp.streaming.InputSevOneRecord)
                                                                     :  +- SerializeFromObject [knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).deviceId AS deviceId#40, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).deviceName, true, false) AS deviceName#41, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).deviceIp, true, false) AS deviceIp#42, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).peerId AS peerId#43, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).objectId AS objectId#44, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).objectName, true, false) AS objectName#45, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).objectDesc, true, false) AS objectDesc#46, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).pluginId AS pluginId#47, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).pluginName, true, false) AS pluginName#48, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).indicatorId AS indicatorId#49, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).indicatorName, true, false) AS indicatorName#50, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).format AS format#51, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).value, true, false) AS value#52, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).time AS time#53, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).clusterName, true, false) AS clusterName#54, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).peerIp, true, false) AS peerIp#55]
                                                                     :     +- MapPartitions org.apache.spark.sql.Dataset$$Lambda$1408/1360791649@3c4e027e, obj#39: yet.another.company.snmp.streaming.InputSevOneRecord
                                                                     :        +- DeserializeToObject cast(value#8 as binary), obj#38: binary
                                                                     :           +- Project [value#8]
                                                                     :              +- StreamingDataSourceV2Relation [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan@7d0b4aa8, KafkaV2[Subscribe[sevone-spdb]]
                                                                     +- TypedFilter yet.another.company.snmp.streaming.SnmpStreaming$$$Lambda$1425/721212816@7fc33109, class yet.another.company.snmp.streaming.InputSevOneRecord, [StructField(deviceId,IntegerType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(peerId,IntegerType,false), StructField(objectId,IntegerType,false), StructField(objectName,StringType,true), StructField(objectDesc,StringType,true), StructField(pluginId,IntegerType,false), StructField(pluginName,StringType,true), StructField(indicatorId,IntegerType,false), StructField(indicatorName,StringType,true), StructField(format,IntegerType,false), StructField(value,StringType,true), StructField(time,DoubleType,false), StructField(clusterName,StringType,true), StructField(peerIp,StringType,true)], newInstance(class yet.another.company.snmp.streaming.InputSevOneRecord)
                                                                        +- SerializeFromObject [knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).deviceId AS deviceId#113, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).deviceName, true, false) AS deviceName#114, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).deviceIp, true, false) AS deviceIp#115, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).peerId AS peerId#116, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).objectId AS objectId#117, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).objectName, true, false) AS objectName#118, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).objectDesc, true, false) AS objectDesc#119, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).pluginId AS pluginId#120, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).pluginName, true, false) AS pluginName#121, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).indicatorId AS indicatorId#122, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).indicatorName, true, false) AS indicatorName#123, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).format AS format#124, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).value, true, false) AS value#125, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).time AS time#126, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).clusterName, true, false) AS clusterName#127, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.streaming.InputSevOneRecord, true])).peerIp, true, false) AS peerIp#128]
                                                                           +- MapPartitions org.apache.spark.sql.Dataset$$Lambda$1408/1360791649@273af89b, obj#112: yet.another.company.snmp.streaming.InputSevOneRecord
                                                                              +- DeserializeToObject cast(value#81 as binary), obj#111: binary
                                                                                 +- Project [value#81]
                                                                                    +- StreamingDataSourceV2Relation [key#80, value#81, topic#82, partition#83, offset#84L, timestamp#85, timestampType#86], org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan@2bba750, KafkaV2[Subscribe[sevone-spdb]]

	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:355)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:245)
Caused by: org.apache.spark.SparkException: Writing job aborted.
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:413)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:361)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:322)
	at org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:329)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:39)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:39)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:45)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3676)
	at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:2980)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3667)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:104)
	at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:227)
	at org.apache.spark.sql.execution.SQLExecution$.executeQuery$1(SQLExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:132)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:104)
	at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:227)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:132)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:248)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:131)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:68)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3665)
	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2980)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:575)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:104)
	at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:227)
	at org.apache.spark.sql.execution.SQLExecution$.executeQuery$1(SQLExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:132)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:104)
	at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:227)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:132)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:248)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:131)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:68)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$15(MicroBatchExecution.scala:570)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:352)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:350)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:69)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:570)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:223)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:352)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:350)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:69)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:191)
	at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:185)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:334)
	... 1 more
Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 1.0 failed 4 times, most recent failure: Lost task 19.3 in stage 1.0 (TID 799, ip-96-113-30-136.nest.r53.xcal.tv, executor 57): org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-735645629-96.113.30.100-1616274425646:blk_1073825835_85149 file=/streaming-jobs--checkpoints/state/0/19/319.snapshot
	at org.apache.hadoop.hdfs.DFSInputStream.refetchLocations(DFSInputStream.java:879)
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:862)
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:841)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:567)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:757)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at net.jpountz.lz4.LZ4BlockInputStream.tryReadFully(LZ4BlockInputStream.java:269)
	at net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:190)
	at net.jpountz.lz4.LZ4BlockInputStream.read(LZ4BlockInputStream.java:142)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.readSnapshotFile(HDFSBackedStateStoreProvider.scala:528)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$3(HDFSBackedStateStoreProvider.scala:376)
	at scala.Option.orElse(Option.scala:447)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$2(HDFSBackedStateStoreProvider.scala:376)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:561)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.loadMap(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getStore(HDFSBackedStateStoreProvider.scala:204)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.get(StateStore.scala:371)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:90)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2215)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2164)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2163)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2163)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1013)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1013)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1013)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2395)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2344)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2333)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:815)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:382)
	... 49 more
Caused by: org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-735645629-96.113.30.100-1616274425646:blk_1073825835_85149 file=/streaming-jobs--checkpoints/state/0/19/319.snapshot
	at org.apache.hadoop.hdfs.DFSInputStream.refetchLocations(DFSInputStream.java:879)
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:862)
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:841)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:567)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:757)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at net.jpountz.lz4.LZ4BlockInputStream.tryReadFully(LZ4BlockInputStream.java:269)
	at net.jpountz.lz4.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:190)
	at net.jpountz.lz4.LZ4BlockInputStream.read(LZ4BlockInputStream.java:142)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.readSnapshotFile(HDFSBackedStateStoreProvider.scala:528)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$3(HDFSBackedStateStoreProvider.scala:376)
	at scala.Option.orElse(Option.scala:447)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$2(HDFSBackedStateStoreProvider.scala:376)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:561)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.loadMap(HDFSBackedStateStoreProvider.scala:356)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getStore(HDFSBackedStateStoreProvider.scala:204)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.get(StateStore.scala:371)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:90)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

	 ApplicationMaster host: ip-96-113-30-138.nest.r53.xcal.tv
	 ApplicationMaster RPC port: 40747
	 queue: default
	 start time: 1616337592025
	 final status: FAILED
	 tracking URL: http://ip-96-113-30-100.nest.r53.xcal.tv:20888/proxy/application_1616274464507_0002/
	 user: hadoop
21/03/21 14:48:08 ERROR Client: Application diagnostics message: Diagnostic messages truncated, showing last 65536 chars out of 80927:
...qdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#838: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
      +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#837: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
         +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#728, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#729, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#730, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#731L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#732, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#733, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#734, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#735, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#736, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#737, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#738, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#739, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#740, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#741, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#742, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#743L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#744, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#745, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#746, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#747, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIp, true, false) AS neighborIp#748, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifIndex AS ifIndex#749, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuType, true, false) AS cpuType#750, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuName, true, false) AS cpuName#751, ... 12 more fields]
            +- MapElements yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1635/308083037@34eab33, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#727: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
               +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#726: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                  +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#617, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#618, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#619, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#620L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#621, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#622, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#623, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#624, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#625, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#626, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#627, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#628, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#629, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#630, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#631, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#632L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#633, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#634, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#635, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#636, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIp, true, false) AS neighborIp#637, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifIndex AS ifIndex#638, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuType, true, false) AS cpuType#639, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuName, true, false) AS cpuName#640, ... 12 more fields]
                     +- MapElements yet.another.company.core.metrics.LongValStatsAccumulator$$Lambda$1633/484875948@7fe58c04, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#616: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                        +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#615: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                           +- TypedFilter yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1630/1394587108@232aa65a, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState)
                              +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#469, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#470, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#471, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#472L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#473, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#474, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#475, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#476, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#477, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#478, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#479, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#480, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#481, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#482, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#483, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#484L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#485, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#486, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#487, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#488, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIp, true, false) AS neighborIp#489, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifIndex AS ifIndex#490, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuType, true, false) AS cpuType#491, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuName, true, false) AS cpuName#492, ... 12 more fields]
                                 +- MapElements yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1629/1058405252@7f200df4, class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, [StructField(uuid,StringType,true), StructField(id,StringType,true), StructField(currValue,DecimalType(38,18),true), StructField(time,LongType,false), StructField(updated,BooleanType,false), StructField(isDiff,BooleanType,false), StructField(diffValue,DoubleType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(ifName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(objectName,StringType,true), StructField(division,StringType,true), StructField(sourceType,StringType,true), StructField(prevTime,LongType,false), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), ... 12 more fields], obj#468: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                                    +- DeserializeToObject newInstance(class yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState), obj#467: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState
                                       +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).uuid, true, false) AS uuid#358, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).id, true, false) AS id#359, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).currValue AS currValue#360, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).time AS time#361L, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).updated AS updated#362, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).isDiff AS isDiff#363, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).diffValue AS diffValue#364, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceName, true, false) AS deviceName#365, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).deviceIp, true, false) AS deviceIp#366, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifName, true, false) AS ifName#367, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifDesc, true, false) AS ifDesc#368, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).indicatorName, true, false) AS indicatorName#369, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).objectName, true, false) AS objectName#370, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).division, true, false) AS division#371, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).sourceType, true, false) AS sourceType#372, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).prevTime AS prevTime#373L, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).vendor, true, false) AS vendor#374, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).model, true, false) AS model#375, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborFqdn, true, false) AS neighborFqdn#376, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIfName, true, false) AS neighborIfName#377, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).neighborIp, true, false) AS neighborIp#378, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).ifIndex AS ifIndex#379, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuType, true, false) AS cpuType#380, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, true])).cpuName, true, false) AS cpuName#381, ... 12 more fields]
                                          +- FlatMapGroupsWithState yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1621/1779687964@58bc59dc, cast(value#284 as string).toString, newInstance(class yet.another.company.snmp.dto.RichSnmpRecord), [value#284], [deviceId#254, deviceName#255, deviceIp#256, objectName#257, ifDesc#258, indicatorName#259, value#260, time#261L, pluginName#262, vendor#263, model#264, neighborFqdn#265, neighborIfName#266, neighborIp#267, ifIndex#268, id#269, sourceType#270, cpuType#271, cpuName#272, ifName#273, division#274, metric#275, status#276, bandwidth#277L, ... 5 more fields], obj#357: yet.another.company.snmp.dataframe.SnmpDataFrameUtils$SnmpAggState, class[uuid[0]: string, id[0]: string, currValue[0]: decimal(38,18), time[0]: bigint, updated[0]: boolean, isDiff[0]: boolean, diffValue[0]: double, deviceName[0]: string, deviceIp[0]: string, ifName[0]: string, ifDesc[0]: string, indicatorName[0]: string, objectName[0]: string, division[0]: string, sourceType[0]: string, prevTime[0]: bigint, vendor[0]: string, model[0]: string, neighborFqdn[0]: string, neighborIfName[0]: string, neighborIp[0]: string, ifIndex[0]: int, cpuType[0]: string, cpuName[0]: string, status[0]: struct<underMaintenance:boolean,inInventory:boolean,neighborUnderMaintenance:boolean>, metric[0]: string, tags[0]: map<string,string>, sysId[0]: string, rate[0]: double, bandwidth[0]: bigint, connectionId[0]: string, history[0]: array<struct<time:bigint,value:decimal(38,18)>>, metaInfo[0]: struct<batchId:bigint>, historyRecords[0]: array<struct<ruleId:string,ruleDescription:string,workflowId:string,className:string,nodeIp:string,eventTime:string>>, forAlarms[0]: boolean, eventLevel[0]: string], Update, false, NoTimeout
                                             +- AppendColumns yet.another.company.snmp.dataframe.SnmpDatasetUtils$$$Lambda$1619/313560769@3dae8418, class yet.another.company.snmp.dto.RichSnmpRecord, [StructField(deviceId,IntegerType,false), StructField(deviceName,StringType,true), StructField(deviceIp,StringType,true), StructField(objectName,StringType,true), StructField(ifDesc,StringType,true), StructField(indicatorName,StringType,true), StructField(value,DecimalType(38,18),true), StructField(time,LongType,false), StructField(pluginName,StringType,true), StructField(vendor,StringType,true), StructField(model,StringType,true), StructField(neighborFqdn,StringType,true), StructField(neighborIfName,StringType,true), StructField(neighborIp,StringType,true), StructField(ifIndex,IntegerType,false), StructField(id,StringType,true), StructField(sourceType,StringType,true), StructField(cpuType,StringType,true), StructField(cpuName,StringType,true), StructField(ifName,StringType,true), StructField(division,StringType,true), StructField(metric,StringType,true), StructField(status,StructType(StructField(underMaintenance,BooleanType,false), StructField(inInventory,BooleanType,false), StructField(neighborUnderMaintenance,BooleanType,true)),true), StructField(bandwidth,LongType,false), ... 5 more fields], newInstance(class yet.another.company.snmp.dto.RichSnmpRecord), [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, input[0, java.lang.String, true], true, false) AS value#284]
                                                +- SerializeFromObjecCommand exiting with ret '1'